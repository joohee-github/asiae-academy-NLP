{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F2stmP_YS22V"
   },
   "source": [
    "온라인상에서 바로 데이터 수집해서 실습 \n",
    "\n",
    "https://www.forbes.com/sites/adrianbridgwater/2019/04/15/what-drove-the-ai-renaissance/#5ba50c691f25\n",
    "# 데이터수집"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2521,
     "status": "ok",
     "timestamp": 1596004746568,
     "user": {
      "displayName": "김현진",
      "photoUrl": "",
      "userId": "10981707102385748924"
     },
     "user_tz": -540
    },
    "id": "ilR9TwSHS22X",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url = 'https://www.forbes.com/sites/adrianbridgwater/2019/04/15/what-drove-the-ai-renaissance/?ss=ai-big-data#45dd5dd61f25'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1612,
     "status": "ok",
     "timestamp": 1596004753358,
     "user": {
      "displayName": "김현진",
      "photoUrl": "",
      "userId": "10981707102385748924"
     },
     "user_tz": -540
    },
    "id": "OB0NfKilS22a",
    "outputId": "49586700-bc79-4f14-991a-bf86de8a9a97"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Italian Renaissance: Vitruvian Man by Leonardo da VinciIt is the present-day darling of the tech world. The current renaissance of Artificial Intelligence (AI) with its sister discipline Machine Learning (ML) has led every IT firm worth its salt to engineer some form of AI onto its platform, into its toolsets and throughout its software applications.IBM CEO Ginni Rometty has already proclaimed that AI will change 100 percent of jobs over the next decade.And yes, she does mean everybody's job fro\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "div = soup.find('div',class_='article-body fs-article fs-responsive-text current-article')\n",
    "p_tag = div.find_all('p')\n",
    "content=''\n",
    "for i in p_tag:\n",
    "    content+=i.text\n",
    "content[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Italian Renaissance: Vitruvian Man by Leonardo da VinciIt is the present-day darling of the tech world. The current renaissance of Artificial Intelligence (AI) with its sister discipline Machine Learning (ML) has led every IT firm worth its salt to engineer some form of AI onto its platform, into its toolsets and throughout its software applications.IBM CEO Ginni Rometty has already proclaimed that AI will change 100 percent of jobs over the next decade.And yes, she does mean everybody\\'s job from yours to mine and onward to the role of grain farmers in Egypt, pastry chefs in Paris and dog walkers in Oregon i.e. every job. We will now be able to help direct all workers’ actions and behavior with a new degree of intelligence that comes from predictive analytics, all stemming from the AI engines we will now increasingly depend upon.\\nWhen did it all go so right?But AI used to be a fanciful notion mostly confined science fiction, so when did it all go right?In recent years we’ve had some big changes in technology. Aside from the proliferation of mobile devices that has impacted us all, memory has become a lot cheaper, data storage has become a lot easier (in cloud, and elsewhere) and computer processing speeds have continued to outstrip previous records. With the power of quantum computing around the corner, is the AI renaissance simply a result of the coming together of these ‘tech ingredient’ forces?“It isn\\'t just massive compute power. There are important algorithmic changes that have been developed. Plus, it is much easier to gain access to more data in an Internet-connected world,” said Ted Dunning, CTO at data platform, AI and analytics company MapR. “All three aspects (compute, algorithms, data) combine to make todays machine learning possible. Also and quite frankly, a lot of applications only need data availability... we could have implemented them 25 years ago pretty easily if the data had been available and the output of the model could have been integrated back into the business flow.”So, in many ways, Dunning really heralds the modern era of the web as the key facilitator for the new age of AI. Information has become not just ubiquitous; it has also become easier to access and more accurately classified into structured, semi-structured and unstructured data in its rawest form.Tuning AI towards lifeDunning and MapR point out that the new generation of AI & ML is now rediscovering ideas, some of which were first thought of some 50 years ago. The difference today is, each time keep adding a bit of something new. A bit of computing power here, better data there, new ideas for organizing and optimizing a network and after a while we get to build new AI systems that really do useful work. So how should we continue to engineer these new systems?\"A key to success [in the new era of AI] is to focus on the design of the human-AI interactions as much as in the AI itself,\" said Jesus Mantas, general manager and managing partner in IBM Global Business Services. “Many AI programs focus primarily on machine learning algorithms and training datasets, but fail to address the most important success factors: the design of human-machine relationships, new AI-powered workflows… and perfecting the choreography of processes, technology and humans. Those programs rarely scale or achieve benefits. The companies succeeding to scale AI and its benefits demonstrate that skilled, purposeful design of workflows and user interactions lead to faster adoption and business benefits.\"CEO of AI code analytics platform company Gamma is Vishal Rai. In general terms, Rai agrees that the AI renaissance has been driven by tectonic shifts in three areas in the computing world: computing power, swathes of data (and its accessibility)… but also by human ingenuity.He points to new developments coming out of both Silicon Valley but further afield also (China being a prime example, Huawei builds its smartphone chipsets around its Kirin AI-enriched microprocessor) and says that this is all helping to create future industries such as autonomous driving and health care diagnostics.Real world application of AI applicationsSo in what ways are the new real world applications of AI manifesting themselves and starting to impact the services we use below the surface?Cloud computing software intelligence and Application Performance Management (APM) specialist Dynatrace has now extended its AI-powered platform to include IBM Z mainframe support for CICS (a mainframe programming language), IMS (a mainframe database) and middleware. To put that in less technical terms, Dynatrace can be used to monitor software that sits on mainframes to make sure it stays healthy.Why bother? Because the mainframe was never built to be hammered by devices with massively busy data streams like mobile banking apps, games and other online niceties. This means we need AI to understand what impact the mainframe is having on the newer systems we build.“While enterprises are moving applications to modern cloud stacks for agility and competitive advantage, these applications often still depend on critical transactions and ‘crown jewels’ customer data residing on IBM Z mainframes. This puts pressure on these resources to perform tasks that were not envisioned when the mainframes were launched,” said Steve Tack, SVP of products at Dynatrace. “Because Dynatrace provides end-to-end hybrid visibility [through our Davis AI engine], customers can optimize new services, catch performance degradations before user impact, and understand exactly who has been impacted by an incident. This enables customers to confidently innovate applications that leverage data from mainframes to increase revenue, build brand loyalty, and create competitive advantage.”AI as a work of artMany would argue that the path to contemporary AI has been a long slog, but the systems we build now keep finding clever shortcuts… so the momentum for the AI renaissance is actually building cumulatively.Some argue that AI never went away and that the current popularization of AI and its ensuing discussion is just a natural progression of a technology that simply needed to come through a period of adolescence. Either way, AI is in your smartphone and in your cloud computing services, so renaissance or not, let’s hope it continues to become a work of art.Renaissance art'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7EjxCgwmS22e"
   },
   "source": [
    "# 영문토큰화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IxvvBIUCULPu"
   },
   "source": [
    "punkt tokenizer 참고 : \n",
    "https://www.nltk.org/_modules/nltk/tokenize/punkt.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1IoeTckuS22f"
   },
   "source": [
    "word_tokenize() : 마침표와 구두점(온점(.), 컴마(,), 물음표(?), 세미콜론(;), 느낌표(!) 등과 같은 기호)으로 구분하여 토큰화\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3848,
     "status": "ok",
     "timestamp": 1596004762627,
     "user": {
      "displayName": "김현진",
      "photoUrl": "",
      "userId": "10981707102385748924"
     },
     "user_tz": -540
    },
    "id": "K8dxcx4HS22g",
    "outputId": "89a2d768-d1f2-40f8-93b4-d27a6d3490be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Italian', 'Renaissance', ':', 'Vitruvian', 'Man', 'by', 'Leonardo', 'da', 'VinciIt', 'is', 'the', 'present-day', 'darling', 'of', 'the', 'tech', 'world', '.', 'The', 'current']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/hyeonjin/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# word_tokenize\n",
    "import nltk\n",
    "# nltk punkt tokenizer download\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "token1 = word_tokenize(content)\n",
    "print(token1[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vVL0HT7aS22i"
   },
   "source": [
    "WordPunctTokenizer() : 알파벳이 아닌문자를 구분하여 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 912,
     "status": "ok",
     "timestamp": 1596005079623,
     "user": {
      "displayName": "김현진",
      "photoUrl": "",
      "userId": "10981707102385748924"
     },
     "user_tz": -540
    },
    "id": "A7uQwEXoS22j",
    "outputId": "24f74d08-c86b-4eff-979d-56bd65fd2bae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Italian', 'Renaissance', ':', 'Vitruvian', 'Man', 'by', 'Leonardo', 'da', 'VinciIt', 'is', 'the', 'present', '-', 'day', 'darling', 'of', 'the', 'tech', 'world', '.']\n"
     ]
    }
   ],
   "source": [
    "# WordPunctTokenizer() : 알파벳이 아닌문자를 구분하여 토큰화\n",
    "import nltk\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "token2 = WordPunctTokenizer().tokenize(content)\n",
    "print(token2[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F2fBCo_tS22l"
   },
   "source": [
    "TreebankWordTokenizer() : 정규표현식에 기반한 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 795,
     "status": "ok",
     "timestamp": 1596005085244,
     "user": {
      "displayName": "김현진",
      "photoUrl": "",
      "userId": "10981707102385748924"
     },
     "user_tz": -540
    },
    "id": "fU8Jbt89S22l",
    "outputId": "497ee4eb-39ae-4e20-fa05-382506ae2a7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Italian', 'Renaissance', ':', 'Vitruvian', 'Man', 'by', 'Leonardo', 'da', 'VinciIt', 'is', 'the', 'present-day', 'darling', 'of', 'the', 'tech', 'world.', 'The', 'current', 'renaissance']\n"
     ]
    }
   ],
   "source": [
    "# TreebankWordTokenizer() : 정규표현식에 기반한 토큰화\n",
    "import nltk\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "token = TreebankWordTokenizer().tokenize(content)\n",
    "print(token[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EU7zX9U1S22n"
   },
   "source": [
    "# 영문 품사부착\n",
    "분리한 토큰마다 품사를 부착한다\n",
    "\n",
    "https://www.nltk.org/api/nltk.tag.html\n",
    "\n",
    "태크목록 : https://pythonprogramming.net/natural-language-toolkit-nltk-part-speech-tagging/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 994,
     "status": "ok",
     "timestamp": 1596005347930,
     "user": {
      "displayName": "김현진",
      "photoUrl": "",
      "userId": "10981707102385748924"
     },
     "user_tz": -540
    },
    "id": "4RkVDQy2S22o",
    "outputId": "29655edd-e74f-40ab-b5f5-a07ec68046f3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/hyeonjin/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import pos_tag\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 838,
     "status": "ok",
     "timestamp": 1596005349536,
     "user": {
      "displayName": "김현진",
      "photoUrl": "",
      "userId": "10981707102385748924"
     },
     "user_tz": -540
    },
    "id": "qgjY5wRqS22r",
    "outputId": "793796b3-ed5e-4495-de9c-2a4da6e04b5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Italian', 'JJ'), ('Renaissance', 'NNP'), (':', ':'), ('Vitruvian', 'JJ'), ('Man', 'NN'), ('by', 'IN'), ('Leonardo', 'NNP'), ('da', 'NN'), ('VinciIt', 'NNP'), ('is', 'VBZ'), ('the', 'DT'), ('present-day', 'JJ'), ('darling', 'NN'), ('of', 'IN'), ('the', 'DT'), ('tech', 'JJ'), ('world', 'NN'), ('.', '.'), ('The', 'DT'), ('current', 'JJ')]\n"
     ]
    }
   ],
   "source": [
    "taggedToken = pos_tag(token1)\n",
    "print(taggedToken[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xiEeFsT0S22s"
   },
   "source": [
    "# 영문 개체명인식\n",
    "http://www.nltk.org/api/nltk.chunk.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 322
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1170,
     "status": "ok",
     "timestamp": 1596005401253,
     "user": {
      "displayName": "김현진",
      "photoUrl": "",
      "userId": "10981707102385748924"
     },
     "user_tz": -540
    },
    "id": "rxV8qk_KS22w",
    "outputId": "ec4d2b29-2280-4b41-a2d5-7b9d41314c80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token: ['Barack', 'Obama', 'likes', 'fried', 'chicken', 'very', 'much']\n",
      "pos-tag: [('Barack', 'NNP'), ('Obama', 'NNP'), ('likes', 'VBZ'), ('fried', 'VBN'), ('chicken', 'JJ'), ('very', 'RB'), ('much', 'JJ')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to /Users/hyeonjin/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /Users/hyeonjin/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/hyeonjin/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (PERSON Barack/NNP)\n",
      "  (ORGANIZATION Obama/NNP)\n",
      "  likes/VBZ\n",
      "  fried/VBN\n",
      "  chicken/JJ\n",
      "  very/RB\n",
      "  much/JJ)\n"
     ]
    }
   ],
   "source": [
    "# 예시 : Barack Obama likes fried chicken very much.\n",
    "# word_tokenize() : 마침표와 구두점(온점(.), 컴마(,), 물음표(?), 세미콜론(;), 느낌표(!) 등과 같은 기호)으로 구분하여 토큰화\n",
    "nltk.download('words')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "# 토큰화 \n",
    "token1 = word_tokenize('Barack Obama likes fried chicken very much')\n",
    "print('token:',token1)\n",
    "# pos-tag\n",
    "taggedToken = pos_tag(token1)\n",
    "print('pos-tag:',taggedToken)\n",
    "# chunking\n",
    "from nltk import ne_chunk\n",
    "neToken = ne_chunk(taggedToken)\n",
    "print(neToken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZCqgRCUgVb21"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "2_텍스트마이닝_실습1_영문_전처리.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
