{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 단어의 표현\n",
    "- 문자열을 숫자로 바꾸는 과정이 필요하다.\n",
    "\n",
    "Local Representation, Distributed Representation\n",
    "\n",
    "- Local Representation은 표현하고자 하는 단어만을 보고 수치화하여 표현한다. 입력한 단어를 인덱스로 표현한다.\n",
    "- Distributed Representation은 주변단어를 참고하여 수치화한다. 원숭이와 코뿔소는 동물로 비슷한 위치에 Embedding, 바나나와 오렌지는 과일로 비슷한 위치에 Embedding원숭이와 바나나는 서로 연관성이 있기 때문에, 유사도가 높기때문에 가까운 위치에 Embedding 된다.\n",
    "- 단어들 사이의 유사도 -> 클러스터링 -> 하나의 주제가 됨\n",
    "\n",
    "Local Representaion\n",
    "- One hot vector : 단어가 3개면 3,3의 행렬, 단어의 갯수를 벡터차원으로 하여 표현하고자 하는 단어의 인덱스에는 '1' 다른 인덱스에는 '0'을 배정 (차원의 문제가 발생한다. 벡터가 단어의 의미를 담지 못함, 유사성이 높은 단어끼리 Embedding하지 못함)\n",
    "- Ngram :\n",
    "- Count based method : boW, TDM\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Representation\n",
    "\n",
    "## One-hot vector 직접구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코딩 대상 단어를 담은 리스트\n",
    "word_ls = ['원숭이', '바나나', '사과', '코끼리']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "# {단어:인덱스} 사전구축\n",
    "# 빈딕셔너리 구축\n",
    "word2id_dic = defaultdict(lambda:len(word2id_dic))\n",
    "\n",
    "# word + 인덱스\n",
    "for word in word_ls:\n",
    "    word2id_dic[word]\n",
    "\n",
    "# 고유단어 갯수 : 4개 \n",
    "# 단어의 갯수만큼 차원이 늘어나기 때문에\n",
    "n_unique_words = len(word2id_dic)\n",
    "# 단어의 갯수만큼 차원을 만들고 전부다 0을 넣는다.\n",
    "one_hot_vectors = np.zeros((len(word_ls), n_unique_words))\n",
    "\n",
    "\n",
    "for i,word in enumerate(word_ls):\n",
    "    index = word2id_dic[word]\n",
    "    # 단어의 고유 인덱스에 1을 더해줌\n",
    "    one_hot_vectors[i, index] +=1\n",
    "one_hot_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot-vector 패키지 사용\n",
    "\n",
    "### sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scikit-learn을 이용해 범주형 데이터를 쉽게 수치형 데이터로 바꿀 수 있다.\n",
    "\n",
    "0과 1로 이루어진 다수의 열을 만드는 one-hot encoder와 달리 label encoder는 하나의 열에 서로 다른 숫자를 입력해준다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing c:\\users\\user\\appdata\\local\\pip\\cache\\wheels\\46\\ef\\c3\\157e41f5ee1372d1be90b09f74f82b10e391eaacca8f22d33e\\sklearn-0.0-py2.py3-none-any.whl\n",
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-0.23.2-cp37-cp37m-win_amd64.whl (6.8 MB)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\user\\.conda\\envs\\study2\\lib\\site-packages (from scikit-learn->sklearn) (1.19.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\user\\.conda\\envs\\study2\\lib\\site-packages (from scikit-learn->sklearn) (0.16.0)\n",
      "Collecting scipy>=0.19.1\n",
      "  Downloading scipy-1.5.2-cp37-cp37m-win_amd64.whl (31.2 MB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Using cached threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
      "Installing collected packages: scipy, threadpoolctl, scikit-learn, sklearn\n",
      "Successfully installed scikit-learn-0.23.2 scipy-1.5.2 sklearn-0.0 threadpoolctl-2.1.0\n"
     ]
    }
   ],
   "source": [
    "! pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sklearnm을 활용한 onr-hot - encoding\n",
    "\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# 예제 데이터 배열\n",
    "values = array(word_ls)\n",
    "\n",
    "#문자열에 숫자를 붙임\n",
    "label_enc = LabelEncoder()\n",
    "# 피팅시키고 transform을 한번에 해줌\n",
    "# LabelEncoder()의 결과로 문자형 변수가 숫자형 변수 범주형으로 변경되게 된다.\n",
    "\n",
    "int_enc = label_enc.fit_transform(values)\n",
    "\n",
    "#binary encode\n",
    "\n",
    "# sparse = False 희소 벡터가 아니라 0과 1로 표현하는 disdrete vector이니까 False로 해준 것.\n",
    "onehot_enc = OneHotEncoder(sparse = False) \n",
    "# n:1 matrix로 변환\n",
    "int_enc = int_enc.reshape(len(int_enc),1)   \n",
    "# 이를 one hot encoder에 fit_transform 해주면, one hot encoding된 결과를 얻을 수 있다.\n",
    "onehot_enc = onehot_enc.fit_transform(int_enc)\n",
    "onehot_enc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ngram\n",
    "- 문맥을 이해할 수 있게 표현한 방법\n",
    "- N개의 연속된 단어 나열\n",
    "- 하나의 토큰 = 유니그램 나는\n",
    "- 두개의 토큰 = 바이그램 나는;오늘\n",
    "- 세개의 토큰 = 트라이그램 나는;오늘;동물원에서\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bag of world\n",
    "- 문서 내 단어출현 순서를 무시하고, 출현 빈도수만으로 단어를 표현하는 방법\n",
    "- 각 토큰에 고유 인덱스를 부여하고 각 인덱스 위치에 토큰 등장 횟수를 기록한다.\n",
    "- 한계 : 단어의 순서를 고려하지 않음, 0으로된 부분이 많이 있음. -> 쓸모없는 공간 낭비, 단어의 빈도수가 중요도를 바로 의미하지 않는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ba gof world 직접 구현\n",
    "\n",
    "docs = ['오늘 동물원에서 코끼리 원숭이를 보고 코끼리 원숭이에게 먹이를 줬어', \n",
    "        '오늘 동물원에서 원숭이에게 사과를 줬어']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['오늘', '동물원에서', '코끼리', '원숭이를', '보고', '코끼리', '원숭이에게', '먹이를', '줬어'],\n",
       " ['오늘', '동물원에서', '원숭이에게', '사과를', '줬어']]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_ls = []\n",
    "for doc in docs:\n",
    "    doc_ls.append(doc.split(' '))\n",
    "doc_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1, 2, 1, 1, 1, 1], [1, 1, 2, 1, 1, 1, 1]]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict \n",
    "# key값이 없을 경우 미리 지정해 놓은 초기값을 반환하는 dictionary\n",
    "import numpy as np\n",
    "\n",
    "# 주어지게 될 단어의 값으로 미리 딕셔너리 선언해놓기\n",
    "word2id_index = defaultdict(lambda :len(word2id_index))\n",
    "\n",
    "# doc_ls 각문장을 토큰화한 리스트\n",
    "for lis in doc_ls:\n",
    "    for word in lis:\n",
    "        # 유니크한 단어 + 인덱스 리스트\n",
    "        word2id_index[word]\n",
    "\n",
    "BoW_ls = []    \n",
    "for i, words in enumerate(doc_ls):\n",
    "    # 유니크인덱스 리스트 만큼 0으로 채워진 np배열\n",
    "    bow = np.zeros(len(word2id_index), dtype = int)\n",
    "    for token in words:\n",
    "        #??????????????????????????\n",
    "        # 1문장, 2문장\n",
    "        bow[word2id_index[token]] += 1\n",
    "    # 1문장, 2문장 리스트로 합치기\n",
    "    BoW_ls.append(bow.tolist())\n",
    "            \n",
    "BoW_ls            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {'오늘': 0,\n",
       "             '동물원에서': 1,\n",
       "             '코끼리': 2,\n",
       "             '원숭이를': 3,\n",
       "             '보고': 4,\n",
       "             '원숭이에게': 5,\n",
       "             '먹이를': 6,\n",
       "             '줬어': 7,\n",
       "             '사과를': 8})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2id_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Ipython in c:\\users\\user\\.conda\\envs\\study2\\lib\\site-packages (7.17.0)\n",
      "Requirement already satisfied: pygments in c:\\users\\user\\.conda\\envs\\study2\\lib\\site-packages (from Ipython) (2.6.1)\n",
      "Requirement already satisfied: jedi>=0.10 in c:\\users\\user\\.conda\\envs\\study2\\lib\\site-packages (from Ipython) (0.17.1)\n",
      "Requirement already satisfied: decorator in c:\\users\\user\\.conda\\envs\\study2\\lib\\site-packages (from Ipython) (4.4.2)\n",
      "Requirement already satisfied: colorama; sys_platform == \"win32\" in c:\\users\\user\\.conda\\envs\\study2\\lib\\site-packages (from Ipython) (0.4.3)\n",
      "Requirement already satisfied: backcall in c:\\users\\user\\.conda\\envs\\study2\\lib\\site-packages (from Ipython) (0.2.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in c:\\users\\user\\.conda\\envs\\study2\\lib\\site-packages (from Ipython) (49.6.0.post20200814)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\user\\.conda\\envs\\study2\\lib\\site-packages (from Ipython) (3.0.5)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\user\\.conda\\envs\\study2\\lib\\site-packages (from Ipython) (0.7.5)\n",
      "Requirement already satisfied: traitlets>=4.2 in c:\\users\\user\\.conda\\envs\\study2\\lib\\site-packages (from Ipython) (4.3.3)\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in c:\\users\\user\\.conda\\envs\\study2\\lib\\site-packages (from jedi>=0.10->Ipython) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\user\\.conda\\envs\\study2\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->Ipython) (0.2.5)\n",
      "Requirement already satisfied: six in c:\\users\\user\\.conda\\envs\\study2\\lib\\site-packages (from traitlets>=4.2->Ipython) (1.15.0)\n",
      "Requirement already satisfied: ipython-genutils in c:\\users\\user\\.conda\\envs\\study2\\lib\\site-packages (from traitlets>=4.2->Ipython) (0.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install Ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-1.1.1-cp37-cp37m-win_amd64.whl (9.4 MB)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\user\\.conda\\envs\\study2\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.15.4 in c:\\users\\user\\.conda\\envs\\study2\\lib\\site-packages (from pandas) (1.19.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\user\\.conda\\envs\\study2\\lib\\site-packages (from pandas) (2020.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\.conda\\envs\\study2\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Installing collected packages: pandas\n",
      "Successfully installed pandas-1.1.1\n"
     ]
    }
   ],
   "source": [
    "! pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorted_vocab [(0, '나는'), (1, '양념'), (2, '치킨을'), (3, '좋아해'), (4, '하지만'), (5, '후라이드'), (6, '싫어해')]\n",
      "vocab ['나는', '양념', '치킨을', '좋아해', '하지만', '후라이드', '싫어해']\n",
      "문서0 : 나는 양념 치킨을 좋아해 하지만 후라이드 치킨을 싫어해\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>나는</th>\n",
       "      <th>양념</th>\n",
       "      <th>치킨을</th>\n",
       "      <th>좋아해</th>\n",
       "      <th>하지만</th>\n",
       "      <th>후라이드</th>\n",
       "      <th>싫어해</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   나는  양념  치킨을  좋아해  하지만  후라이드  싫어해\n",
       "0   1   1    2    1    1     1    1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "문서1 : 나는 후라이드 치킨을 좋아해 하지만 양념 치킨을 싫어해\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>나는</th>\n",
       "      <th>양념</th>\n",
       "      <th>치킨을</th>\n",
       "      <th>좋아해</th>\n",
       "      <th>하지만</th>\n",
       "      <th>후라이드</th>\n",
       "      <th>싫어해</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   나는  양념  치킨을  좋아해  하지만  후라이드  싫어해\n",
       "0   1   1    2    1    1     1    1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from IPython.core import display as ICD\n",
    "import pandas as pd\n",
    "sorted_vocab = sorted((value, key) for key, value in word2id_index.items())\n",
    "print('sorted_vocab', sorted_vocab)\n",
    "\n",
    "vocab = []\n",
    "for v in sorted_vocab:\n",
    "    vocab.append(v[1])\n",
    "print('vocab', vocab)\n",
    "for i in range(len(docs)):\n",
    "    print('문서{} : {}'.format(i, docs[i]))\n",
    "    ICD.display(pd.DataFrame([BoW_ls[i]],columns =  vocab))\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 단어의 순서를 고려하지 않은 BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = ['나는 양념 치킨을 좋아해 하지만 후라이드 치킨을 싫어해',\n",
    "       '나는 후라이드 치킨을 좋아해 하지만 양념 치킨을 싫어해']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['나는', '양념', '치킨을', '좋아해', '하지만', '후라이드', '치킨을', '싫어해'],\n",
       " ['나는', '후라이드', '치킨을', '좋아해', '하지만', '양념', '치킨을', '싫어해']]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_ls = []\n",
    "for doc in docs:\n",
    "    doc_ls.append(doc.split())\n",
    "doc_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1, 2, 1, 1, 1, 1], [1, 1, 2, 1, 1, 1, 1]]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "word2id = defaultdict(lambda :len(word2id))\n",
    "\n",
    "# 토큰화 + 인덱스 리스트 만들기\n",
    "\n",
    "for lis in doc_ls:\n",
    "    for token in lis:\n",
    "        word2id[token]\n",
    "        \n",
    "boW_ls = []\n",
    "\n",
    "for i, words in enumerate(doc_ls):\n",
    "    bow = np.zeros(len(word2id), dtype = int)\n",
    "    for token in words:\n",
    "        bow[word2id[token]] +=1\n",
    "    boW_ls.append(bow.tolist())\n",
    "boW_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 토큰 빈도 계산\n",
    "- count_vect\n",
    "- 토큰의 이름을 출력하려면 get_feture_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "BoW = count_vect.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서0 : 나는 양념 치킨을 좋아해 하지만 후라이드 치킨을 싫어해\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>나는</th>\n",
       "      <th>싫어해</th>\n",
       "      <th>양념</th>\n",
       "      <th>좋아해</th>\n",
       "      <th>치킨을</th>\n",
       "      <th>하지만</th>\n",
       "      <th>후라이드</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   나는  싫어해  양념  좋아해  치킨을  하지만  후라이드\n",
       "0   1    1   1    1    2    1     1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "문서1 : 나는 후라이드 치킨을 좋아해 하지만 양념 치킨을 싫어해\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>나는</th>\n",
       "      <th>싫어해</th>\n",
       "      <th>양념</th>\n",
       "      <th>좋아해</th>\n",
       "      <th>치킨을</th>\n",
       "      <th>하지만</th>\n",
       "      <th>후라이드</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   나는  싫어해  양념  좋아해  치킨을  하지만  후라이드\n",
       "0   1    1   1    1    2    1     1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from IPython.core import display as ICD\n",
    "import pandas as pd\n",
    "\n",
    "vocab = count_vect.get_feature_names()\n",
    "for i in range(len(docs)):\n",
    "    print('문서{} : {}'.format(i,docs[i]))\n",
    "    ICD.display(pd.DataFrame([BoW.toarray()[i]], columns =  vocab))\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-3.8.3-cp37-cp37m-win_amd64.whl (24.2 MB)\n",
      "Collecting Cython==0.29.14\n",
      "  Downloading Cython-0.29.14-cp37-cp37m-win_amd64.whl (1.7 MB)\n",
      "Requirement already satisfied: numpy>=1.11.3 in c:\\users\\user\\.conda\\envs\\study2\\lib\\site-packages (from gensim) (1.19.1)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\user\\.conda\\envs\\study2\\lib\\site-packages (from gensim) (1.5.2)\n",
      "Collecting smart-open>=1.8.1\n",
      "  Downloading smart_open-2.1.0.tar.gz (116 kB)\n",
      "Requirement already satisfied: six>=1.5.0 in c:\\users\\user\\.conda\\envs\\study2\\lib\\site-packages (from gensim) (1.15.0)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\.conda\\envs\\study2\\lib\\site-packages (from smart-open>=1.8.1->gensim) (2.24.0)\n",
      "Collecting boto\n",
      "  Downloading boto-2.49.0-py2.py3-none-any.whl (1.4 MB)\n",
      "Collecting boto3\n",
      "  Downloading boto3-1.14.47-py2.py3-none-any.whl (129 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\.conda\\envs\\study2\\lib\\site-packages (from requests->smart-open>=1.8.1->gensim) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\user\\.conda\\envs\\study2\\lib\\site-packages (from requests->smart-open>=1.8.1->gensim) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\user\\.conda\\envs\\study2\\lib\\site-packages (from requests->smart-open>=1.8.1->gensim) (1.25.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\user\\.conda\\envs\\study2\\lib\\site-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\n",
      "Collecting botocore<1.18.0,>=1.17.47\n",
      "  Downloading botocore-1.17.47-py2.py3-none-any.whl (6.5 MB)\n",
      "Collecting jmespath<1.0.0,>=0.7.1\n",
      "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting s3transfer<0.4.0,>=0.3.0\n",
      "  Downloading s3transfer-0.3.3-py2.py3-none-any.whl (69 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\user\\.conda\\envs\\study2\\lib\\site-packages (from botocore<1.18.0,>=1.17.47->boto3->smart-open>=1.8.1->gensim) (2.8.1)\n",
      "Collecting docutils<0.16,>=0.10\n",
      "  Downloading docutils-0.15.2-py3-none-any.whl (547 kB)\n",
      "Building wheels for collected packages: smart-open\n",
      "  Building wheel for smart-open (setup.py): started\n",
      "  Building wheel for smart-open (setup.py): finished with status 'done'\n",
      "  Created wheel for smart-open: filename=smart_open-2.1.0-py3-none-any.whl size=110324 sha256=1418d0c76e3520d61d176ac9127755225ac9f80387f2c80e41ac0d4b088571ef\n",
      "  Stored in directory: c:\\users\\user\\appdata\\local\\pip\\cache\\wheels\\56\\b5\\6d\\86dbe4f29d4688e5163a8b8c6b740494310040286fca4dc648\n",
      "Successfully built smart-open\n",
      "Installing collected packages: Cython, boto, docutils, jmespath, botocore, s3transfer, boto3, smart-open, gensim\n",
      "  Attempting uninstall: docutils\n",
      "    Found existing installation: docutils 0.16\n",
      "    Uninstalling docutils-0.16:\n",
      "      Successfully uninstalled docutils-0.16\n",
      "Successfully installed Cython-0.29.14 boto-2.49.0 boto3-1.14.47 botocore-1.17.47 docutils-0.15.2 gensim-3.8.3 jmespath-0.10.0 s3transfer-0.3.3 smart-open-2.1.0\n"
     ]
    }
   ],
   "source": [
    "! pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from gensim import corpora\n",
    "doc_ls = []\n",
    "for doc in docs:\n",
    "    # 토큰화\n",
    "    doc_ls.append(doc.split())\n",
    "    # \n",
    "id2word = corpora.Dictionary(doc_ls)\n",
    "\n",
    "BoW = []\n",
    "for doc in doc_ls:\n",
    "    BoW.append(id2word.doc2bow(doc))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서0 : 나는 양념 치킨을 좋아해 하지만 후라이드 치킨을 싫어해\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>나는</th>\n",
       "      <th>싫어해</th>\n",
       "      <th>양념</th>\n",
       "      <th>좋아해</th>\n",
       "      <th>치킨을</th>\n",
       "      <th>하지만</th>\n",
       "      <th>후라이드</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    나는  싫어해   양념  좋아해  치킨을  하지만  후라이드\n",
       "0  1.0  1.0  1.0  1.0  2.0  1.0   1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "문서1 : 나는 후라이드 치킨을 좋아해 하지만 양념 치킨을 싫어해\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>나는</th>\n",
       "      <th>싫어해</th>\n",
       "      <th>양념</th>\n",
       "      <th>좋아해</th>\n",
       "      <th>치킨을</th>\n",
       "      <th>하지만</th>\n",
       "      <th>후라이드</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    나는  싫어해   양념  좋아해  치킨을  하지만  후라이드\n",
       "0  1.0  1.0  1.0  1.0  2.0  1.0   1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from gensim.matutils import sparse2full\n",
    "from IPython.core import display as ICD\n",
    "import pandas as pd\n",
    "vocab = [id2word[i] for i in id2word.keys()]\n",
    "for i in range(len(docs)):\n",
    "    print('문서{} : {}'.format(i,docs[i]))\n",
    "    ICD.display(pd.DataFrame([sparse2full(BoW[0], len(vocab))], columns = vocab))\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mecab을 사용해서 토큰화를 하고 리스트에 담겨있는 것을 ,를 없애고 공백으로 대신 넣은다음에 이 문장을 doc에 넣고 공백으로 분리해서 boW 생성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
